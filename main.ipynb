{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optical character recognition for documents processing\n",
    "## External solution\n",
    "*Python version 3.10*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "import skimage\n",
    "from easyocr import Reader"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "files_collection = [f\"{i}.jpeg\" for i in range(10)]\n",
    "files_collection.pop(4)\n",
    "files_collection.append(\"4.png\")\n",
    "files_location = \" DataForOCR\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "images = [skimage.io.imread(f\"{files_location}/{url}\")\n",
    "          for url in files_collection]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "new_reader = Reader(lang_list=[\"ru\"])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "group_text = [new_reader.readtext(image=im,\n",
    "                                  batch_size=3,\n",
    "                                  detail=0)\n",
    "              for im in images]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Filter out single-character & non-alphabet predictions\n",
    "# Print some meaningful results\n",
    "\n",
    "pprint([inner_item\n",
    "        for item in group_text\n",
    "        for inner_item in item\n",
    "        if len(inner_item) >= 2 and inner_item.isalpha()])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## My Solution"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.color import rgb2gray\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "d = {chr(i + 1040): i + 1 for i in range(32)}  # No letter \"Ñ‘\"\n",
    "d.update({\" \": 0})\n",
    "inverted_d = {value: key for key, value in d.items()}\n",
    "len_full_name = 36  # let this be maximum full name length\n",
    "\n",
    "\n",
    "def char_to_num(character_string, flag=True):\n",
    "    character_list = list(character_string)\n",
    "    character_numbers = [d[item] for item in character_list]\n",
    "\n",
    "    if flag:\n",
    "        while len(character_numbers) < len_full_name:\n",
    "            character_numbers.append(0)\n",
    "\n",
    "    return character_numbers\n",
    "\n",
    "\n",
    "def num_to_char(character_numbers):\n",
    "    return [inverted_d.get(item, \"_\") for item in character_numbers]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def transform_features(features,\n",
    "                       ind_slice=None, flag=None, reshape_flag=True,\n",
    "                       gray_flag=True, normal_flag=False):\n",
    "    features = features.as_numpy_iterator()\n",
    "    if gray_flag:\n",
    "        lst_to_crop = [rgb2gray(item) for item in features]\n",
    "    else:\n",
    "        lst_to_crop = [item for item in features]\n",
    "\n",
    "    if flag == \"val\":\n",
    "        features = np.array(lst_to_crop[ind_slice:], dtype=np.float64)\n",
    "    elif flag == \"train\":\n",
    "        features = np.array(lst_to_crop[:ind_slice], dtype=np.float64)\n",
    "    else:\n",
    "        features = np.array(lst_to_crop, dtype=np.float64)\n",
    "\n",
    "    if reshape_flag:\n",
    "        n, nx, ny = features.shape\n",
    "        features = features.reshape((n, nx * ny))\n",
    "\n",
    "    if normal_flag:\n",
    "        norm = tf.keras.layers.Rescaling(scale=1.0 / 255.0)\n",
    "        features = norm(features)\n",
    "\n",
    "    return features"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def reverse_flat_categories(array, initial_shape):\n",
    "    res = tf.keras.layers.Reshape((initial_shape[1], initial_shape[2]))\n",
    "\n",
    "    return np.argmax(res(array), axis=2)\n",
    "\n",
    "\n",
    "def reverse_flat_continuous(array, initial_shape):\n",
    "    res = tf.keras.layers.Reshape((initial_shape[1], initial_shape[2]))\n",
    "\n",
    "    return res(array)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "*Load data*"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with open(\"labels.txt\") as f:\n",
    "    dt = f.read().split(\"\\n\")\n",
    "    labels = np.array(list(map(char_to_num, dt)), dtype=np.int64)\n",
    "\n",
    "with open(\"extra_labels.txt\") as f:\n",
    "    extra_dt = f.read().split(\"\\n\")\n",
    "    extra_labels = np.array(list(map(char_to_num, extra_dt)), dtype=np.int64)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "img_height = 224\n",
    "img_width = 224\n",
    "entry_features = tf.keras.utils.image_dataset_from_directory(\n",
    "    files_location,\n",
    "    image_size=(img_height, img_width), interpolation=\"bicubic\",\n",
    "    batch_size=None, shuffle=False, labels=None)\n",
    "extra_entry_features = tf.keras.utils.image_dataset_from_directory(\n",
    "    \"ExtraData\",\n",
    "    image_size=(img_height, img_width), interpolation=\"bicubic\",\n",
    "    batch_size=None, shuffle=False, labels=None)\n",
    "extra_eval_data = tf.keras.utils.image_dataset_from_directory(\n",
    "    \"TestData\",\n",
    "    image_size=(img_height, img_width), interpolation=\"bicubic\",\n",
    "    batch_size=None, shuffle=False, labels=None)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "combined_features_dataset = entry_features.concatenate(extra_entry_features)\n",
    "tf_features = tf.convert_to_tensor(transform_features(combined_features_dataset,\n",
    "                                                      reshape_flag=False,\n",
    "                                                      gray_flag=False, normal_flag=True))\n",
    "tf_labels = tf.convert_to_tensor(np.concatenate((labels, extra_labels), axis=0))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cat_label_group = tf.keras.utils.to_categorical(tf_labels, num_classes=33)\n",
    "cat_label_group_shape = cat_label_group.shape\n",
    "flat = tf.keras.layers.Flatten()\n",
    "flat_label_group = flat(cat_label_group)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "*Training and plotting*"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def train_model(model,\n",
    "                feature_set, epochs, label_set,\n",
    "                validation_split, batch_size=None):\n",
    "    history = model.fit(x=feature_set, y=label_set, batch_size=batch_size,\n",
    "                        epochs=epochs, shuffle=True,\n",
    "                        validation_split=validation_split)\n",
    "    epochs = history.epoch\n",
    "\n",
    "    hist = pd.DataFrame(history.history)\n",
    "    mse1, mse2, acc1, acc2 = hist[\"loss\"], hist[\"val_loss\"],\\\n",
    "                             hist[\"accuracy\"], hist[\"val_accuracy\"]\n",
    "\n",
    "    return epochs, mse1, mse2, acc1, acc2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def plot_the_loss_curve(epochs, mse1, mse2):\n",
    "    plt.figure()\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.plot(epochs, mse1, label=\"Training\")\n",
    "    plt.plot(epochs, mse2, label=\"Validation\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_accuracy(epochs, acc1, acc2):\n",
    "    plt.figure()\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.plot(epochs, acc1, label=\"Training\")\n",
    "    plt.plot(epochs, acc2, label=\"Validation\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def construct_model(set_learning_rate, output_dims=60, inp_shape=(500, 500, 3)):\n",
    "    model = tf.keras.models.Sequential()\n",
    "\n",
    "    # VGG-16 like\n",
    "    model.add(tf.keras.layers.Conv2D(input_shape=inp_shape,\n",
    "                                     filters=64, kernel_size=(3, 3), padding=\"same\",\n",
    "                                     activation=\"tanh\"))\n",
    "    model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=(3, 3), padding=\"same\",\n",
    "                                     activation=\"tanh\"))\n",
    "    model.add(tf.keras.layers.MaxPool2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "    model.add(tf.keras.layers.Conv2D(filters=128, kernel_size=(3, 3), padding=\"same\",\n",
    "                                     activation=\"tanh\"))\n",
    "    model.add(tf.keras.layers.Conv2D(filters=128, kernel_size=(3, 3), padding=\"same\",\n",
    "                                     activation=\"tanh\"))\n",
    "    model.add(tf.keras.layers.MaxPool2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "    model.add(tf.keras.layers.Conv2D(filters=256, kernel_size=(3, 3), padding=\"same\",\n",
    "                                     activation=\"tanh\"))\n",
    "    model.add(tf.keras.layers.Conv2D(filters=256, kernel_size=(3, 3), padding=\"same\",\n",
    "                                     activation=\"tanh\"))\n",
    "    model.add(tf.keras.layers.Conv2D(filters=256, kernel_size=(3, 3), padding=\"same\",\n",
    "                                     activation=\"tanh\"))\n",
    "    model.add(tf.keras.layers.MaxPool2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "    model.add(tf.keras.layers.Conv2D(filters=512, kernel_size=(3, 3), padding=\"same\",\n",
    "                                     activation=\"tanh\"))\n",
    "    model.add(tf.keras.layers.Conv2D(filters=512, kernel_size=(3, 3), padding=\"same\",\n",
    "                                     activation=\"tanh\"))\n",
    "    model.add(tf.keras.layers.Conv2D(filters=512, kernel_size=(3, 3), padding=\"same\",\n",
    "                                     activation=\"tanh\"))\n",
    "    model.add(tf.keras.layers.MaxPool2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "    model.add(tf.keras.layers.Conv2D(filters=512, kernel_size=(3, 3), padding=\"same\",\n",
    "                                     activation=\"tanh\"))\n",
    "    model.add(tf.keras.layers.Conv2D(filters=512, kernel_size=(3, 3), padding=\"same\",\n",
    "                                     activation=\"tanh\"))\n",
    "    model.add(tf.keras.layers.Conv2D(filters=512, kernel_size=(3, 3), padding=\"same\",\n",
    "                                     activation=\"tanh\"))\n",
    "    model.add(tf.keras.layers.MaxPool2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    model.add(tf.keras.layers.Dense(units=4096, activation=\"relu\"))\n",
    "    model.add(tf.keras.layers.Dense(units=4096, activation=\"relu\"))\n",
    "    model.add(tf.keras.layers.Dense(units=output_dims,\n",
    "                                    activation=\"softmax\"))\n",
    "\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adadelta(),\n",
    "                  loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "                  metrics=tf.keras.metrics.Accuracy())\n",
    "\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "learning_rate = 0.9999\n",
    "epochs = 30\n",
    "batch_size = 9\n",
    "validation_split = 0.1\n",
    "\n",
    "new_fit = construct_model(\n",
    "    learning_rate,\n",
    "    output_dims=flat_label_group.shape[1],\n",
    "    inp_shape=(img_height, img_width, 3)\n",
    ")\n",
    "epochs, mse1, mse2, acc1, acc2 = train_model(model=new_fit,\n",
    "                                             feature_set=tf_features,\n",
    "                                             epochs=epochs,\n",
    "                                             label_set=flat_label_group,\n",
    "                                             batch_size=batch_size,\n",
    "                                             validation_split=validation_split)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_the_loss_curve(epochs, mse1, mse2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_accuracy(epochs, acc1, acc2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# tf.keras.utils.plot_model(new_fit)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "new_fit.summary()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "out = new_fit.predict(\n",
    "    x=tf.convert_to_tensor(transform_features(\n",
    "        extra_eval_data,\n",
    "        reshape_flag=False,\n",
    "        gray_flag=False,\n",
    "        normal_flag=True\n",
    "    )),\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pprint(list(map(\n",
    "    lambda x: ''.join(num_to_char(x)),\n",
    "    reverse_flat_categories(out, cat_label_group_shape)\n",
    ")))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
